The partner wants us to replicate the blind source separation algorithm used in @negro_muceli_castronovo_holobar_farina_2016 to decompose raw EMG signals into their constituent motor unit spike trains. This algorithm provides advantages to other blind source separation algorithms in that it is an experimentally validated algorithm that allows for the decomposition of multi-channel invasive EMG and non-invasive EMG data.

Essentially, the blind source separation algorithm is an unsupervised machine learning model that iteratively extracts separation vectors from the data. Separation vectors are vectors that, when applied to the pre-processed data, separate a single motor unit spike train from unwanted noise and other motor unit spike trains. A motor unit spike train contains the firing times of a single motor unit, and it is the mixture of these that compose the raw EMG signal.

Separation vectors are extracted through broadly three steps:

1.  The data is pre-processed.
2.  Latent component analysis (LCA) is performed to estimate a separation vector.
3.  The refinement process is used to increase the quality of the estimated separation vector.

Steps two and three are repeated for a predetermined amount of iterations of the overall blind source separation algorithm.

**Step 1: Pre-Processing.**

The first step of the algorithm is data pre-processing and consists of four sub-steps:

**a.** First, the data is *band-pass filtered.* That removes significant amount of noise from the data.

**b.** Then, the data is *centered* by subtracting the mean of each channel per channel. This process is essencial for LCA to extract all of the separation vectors.

**c.** Then each channel is *extended* by a certain number of time-delayed versions of that channel. This process converts the mixture of signals from a convolutive mixture to a linear instantaneous mixture. This is also a critical step in order to ready the data for LCA [@negro_muceli_castronovo_holobar_farina_2016; @weenink_2012].

**d.** Finally, the data is *whitened*, so that the covariance matrix of the extended channels is equal to the identity matrix. This improves performance by computationally simplifying the convergence of the LCA step [@hyv√§rinen_karhunen_oja_2001].

**Step 2: Latent Component Analysis.**

The pre-processed data then goes through the LCA step. The LCA step is based off of independent component analysis, where the separation vectors would be obtained by maximizing their statistical independence from each other. However, since the motor unit spike trains are extended along with the observations, they cannot be fully independent. This is why LCA extracts separation vectors by maximizing sparsity instead of independence. Intuitively, this is done because a singular motor unit spike train will be more sparse than the combination of multiple motor unit spike trains [@negro_muceli_castronovo_holobar_farina_2016].

**a.** First, the separation vector is *initialized* by using a time instance of high activity in the whitened data, as these time instances are likely to correspond to multiple motor unit firings.

**b.** Using a contrast function that measures sparsity of the motor unit spike train, the estimated separation vector is *iteratively updated*. In each iteration, the estimated separation vectors are orthogonalized against previously accepted separation vectors and normalized, to increase the number of wxtracted unique motor unit spike trains.

**c.** The LCA step converges. This happens when the separation vector no longer changes, within a tolerance.

**Step 3: Refinement.**

After the separation vector is extracted, it goes through the refinement step. This is done because the latent component analysis may converge to unreliable estimates and through refinement the quality of the estimate is increased. The refinement step is an iterative algorithm that maximizes the regularity of the motor unit spike train. This process is carried out under the assumption that singular motor units fire off action potentials at a much more regular rate than combinations of motor units [@negro_muceli_castronovo_holobar_farina_2016].

**a.** First, the motor unit spike train is estimated by applying the separation vector to the pre-processed data.

**b.** Then, the firing times are determined by applying the peak-finding algorithm from @2020SciPy-NMeth. Of these firing times, the instances that correspond to small peaks in the spike train are separated away from the large peaks using the KMeans algorithm from @scikit-learn. The firing times corresponding to small peaks are discarded as they likely correspond to the firing occurrence of more than one motor unit [@negro_muceli_castronovo_holobar_farina_2016]. The information from the accepted firing times are used to update the separation vector.

**c.** The iterative refinement process converges once the coefficient of variation of the time between firings increases.

Once the refinement process is done, the refined separation vector is accepted based on a user-defined threshold of either the silhouette score between the signal and the noise or the pulse-to-noise ratio. The accepted separation vectors correspond to the motor units that the blind source separation algorithm extracts from the raw signal.

A further improvement to the algorithm that we did not have time to implement would be a re-learning feature. The user would run the algorithm on a sample of the data, and based on that sample identify firing times that are inaccurate. Then they would run the algorithm on the rest of the data and based on the firing times identified as inaccurate, the algorithm would no longer make similar mistakes in the rest of the decomposition. Implementing this feature would be quite complex because it is unclear how this would be done. One idea was that we somehow change the initialization of the separation vectors so that they no longer identify the false firing times when applied to the pre-processed data. However, since the separation vector changes throughout the LCA and refinement processes, it would be hard to control the effect that it actually has on the estimated firing times. Another approach would be to influence the KMeans algorithm so that the threshold for the small peaks cluster includes the peaks that were as false firings, in the hopes that future peaks of similar size are also false firings. The downside to this approach would be that we may increase the amount of incorrect identifications of large peaks as small peaks, which are discarded.

The stakeholders affected by our blind source separation algorithm are researchers and those that would be affected by their research. This is why it is important our algorithm works properly so that researchers results are accurate and do not affect the general public adversely down the line. For example, if someone uses `EMGdecomPy` and obtains inaccurate results, and these results are used to inform a neuromuscular diagnosis down the line, it could greatly affect someone's life. Periodically, the results of our algorithm should be compared to others to obtain a second opinion on the decomposition of the EMG signal. We have not had the chance to thoroughly validate our algorithm, as the debugging process took a great deal of time. We have only received qualitative results, obtained by visually comparing MUAP shapes identified by `EMGdecomPy` and those @Hug2021 identified using the `DEMUSE` tool. There are concerns with this approach as the `DEMUSE` software uses a similar but different algorithm than @negro_muceli_castronovo_holobar_farina_2016. The `DEMUSE` software is a highly validated software in comparison to `OTBioLab+`, and therefore the partner wishes to compare our results to theirs.
