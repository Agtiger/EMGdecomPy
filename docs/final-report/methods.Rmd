The partner wants us to replicate the blind source separation algorithm used in @negro_muceli_castronovo_holobar_farina_2016 to decompose raw EMG signals into their constituent motor unit spike trains. This algorithm provides advantages to other blind source separation algorithms in that it is an experimentally validated algorithm that allows for the decomposition of multi-channel invasive EMG and non-invasive EMG data.

Essentially, the blind source separation algorithm is an unsupervised machine learning model that iteratively extracts separation vectors from the data. Separation vectors are vectors that, when applied to the pre-processed data, separate a single motor unit spike train from unwanted noise and other motor unit spike trains. A motor unit spike train contains the firing times of a single motor unit, and it is the mixture of these This is done through broadly three steps:

1. The data is pre-processed.
2. Latent component analysis (LCA) is performed to estimate a separation vector.
3. The refinement process is used to increase the quality of the estimated separation vector.

Steps two and three are repeated for a pre-determined amount of iterations of the overall blind source separation algorithm.

The first step of the algorithm is data pre-processing. Pre-processing occurs in a four step process. First the data is band-pass filtered. Then each channel is centred by subtracting the mean of each channel. Then each channel is extended by a certain number of time-delayed versions of that channel. Finally, the data is whitened, so that the covariance matrix of the channels and their extensions is equal to the identity matrix. Band-pass filtering removes noise, and increases the amount of unique motor units identified. Centering the data makes the whitening process faster and is necessary for LCA to find all of the separation vectors. Extending the data is done for the purpose of converting the mixture of signals from a convolutive mixture to a linear instantaneous mixture, which is necessary for latent component analysis to work [@negro_muceli_castronovo_holobar_farina_2016; @weenink_2012]. Whitening is done to computationally simplify and speed up the convergence of the LCA step [@hyv√§rinen_karhunen_oja_2001].

The pre-processed data then goes through the LCA step. The LCA step is based off of independent component analysis, where the separation vectors would be obtained by maximizing their statistical independence from each other. However, since the motor unit spike trains are extended along with the observations, they cannot be fully independent from each other. This is why LCA extracts separation vectors by maximizing sparsity instead of independence. Intuitively, this is done because a singular motor unit spike train will always be more sparse than the combination of multiple motor unit spike trains [@negro_muceli_castronovo_holobar_farina_2016]. First, the separation vector is initialized by using a time instance of high activity in the whitened data, as these time instances are likely to correspond to multiple motor unit firings. Using a contrast function that measures sparsity of the motor unit spike train, the estimated separation vector is iteratively updated. In each iteration, the estimated separation vectors are orthogonalized against previously accepted separation vectors and normalized, to increase the number of unique motor unit spike trains that are extracted.  The LCA step converges when the separation vector no longer changes, within a tolerance.

After the separation vector is extracted, it goes through the refinement step. This is done because the latent component analysis may converge to unreliable estimates and through refinement the quality of the estimate is increased. The refinement step is an iterative algorithm that maximizes the regularity of the motor unit spike train. This process is carried out under the assumption that singular motor units will fire off action potentials at a much more regular rate than combinations of motor units [@negro_muceli_castronovo_holobar_farina_2016]. First, the motor unit spike train is estimated by applying the separation vector to the pre-processed data. Then the firing times are determined by applying the peak-finding algorithm from @2020SciPy-NMeth. Of these firing times, the instances that correspond to small peaks in the spike train are separated away from the large peaks using the KMeans algorithm from @scikit-learn. The firing times corresponding to small peaks are discarded as they likely correspond to the firing occurrence of more than one motor unit [@negro_muceli_castronovo_holobar_farina_2016]. The information from the accepted firing times are used to update the separation vector. The iterative refinement process converges once the coefficient of variation of the time between firings increases, which in other words means the regularity decreases.

Once the refinement process is done, the refined separation vector is accepted based on a user-defined threshold of either the silhouette score between the signal and the noise or the pulse-to-noise ratio. The accepted separation vectors correspond to the motor units that the blind source separation algorithm extracts from the raw signal.

A further improvement to the algorithm that we we did not have time to implement would be a re-learning feature. The user would run the algorithm on a sample of the data, and based on that sample identify firing times that are inaccurate. Then they would run the algorithm on the rest of the data and based on the firing times identified as inaccurate, the algorithm  would no longer make similar mistakes in the rest of the decomposition. Implementing this feature would be quite complex because it is unclear how this would be done. One idea was that we somehow change the initialization of the separation vectors so that they no longer identity the false firing times when applied to the pre-processed data. However, since the separation vector changes throughout the LCA and refinement processes, it would be hard to control the effect that it actually has on the estimated firing times. Another approach would be to influence the KMeans algorithm so that the threshold for the small peaks cluster includes the peaks that were  as false firings, in the hopes that future peaks of similar size are also false firings. The downside to this approach would be that we may increase the amount of incorrect identifications of large peaks as small peaks, which are discarded.

The stakeholders affected by our blind source separation algorithm are researchers and those that would be affected by their research. This is why it is important our algorithm works properly so that researchers results are accurate and do not affect the general public adversely down the line. For example, if someone uses `EMGdecomPy` and obtains inaccurate results, and these results are used to inform a neuromuscular diagnosis down the line, it could greatly affect someone's life. We have not had the chance to thoroughly validate our algorithm, as the debugging process took a great deal of time. We have only received qualitative results, obtained by  visually comparing MUAP shapes identified by `EMGdecomPy` and those @Hug2021 identified using the `DEMUSE` tool. There are concerns with this approach as the `DEMUSE` software uses a similar but different algorithm than @negro_muceli_castronovo_holobar_farina_2016. The `DEMUSE` software is a highly validated software in comparison to `OT Bioelettronica`, and therefore the partner wishes to compare our results to theirs.
