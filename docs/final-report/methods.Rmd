The partner wants us to replicate the blind-source separation algorithm used in @negro_muceli_castronovo_holobar_farina_2016 to decompose raw EMG signals into their constituent motor unit spike trains. This algorithm provides advantages to other blind-source separation algorithms in that it is an experimentally validated algorithm that allows for the decomposition of multi-channel invasive EMG and non-invasive EMG data.

Essentially, the blind-source separation algorithm is an unsupervised machine learning model that iteratively extracts separation vectors from the data. Separation vectors are vectors that, when applied to the pre-processed data, separate a single motor unit spike train from unwanted noise and other motor unit spike trains. A motor unit spike train contains the firing times of a single motor unit, and it is the mixture of these This is done through broadly three steps:

1. The data is pre-processed.
2. Latent component analysis (LCA) is performed to estimate a separation vector.
3. The refinement process is used to increase the quality of the estimated separation vector.

Steps two and three are repeated for a pre-determined amount of iterations of the overall blind-source separation algorithm.

The first step of the algorithm is data pre-processing. Pre-processing occurs in a three step process. First the data from each channel is centred by subtracting the mean of each channel. Then each channel is extended by a certain number of time-delayed versions of that channel. Finally, the data is whitened, so that the covariance matrix of the channels and their extensions is equal to the identity matrix. Centering the data makes the whitening process faster and is necessary for LCA to find all of the separation vectors. Extending the data is done for the purpose of converting the mixture of signals from a convolutive mixture to a linear instantaneous mixture, which is necessary for latent component analysis to work [@negro_muceli_castronovo_holobar_farina_2016; @weenink_2012]. Whitening is done to computationally simplify and speed up the convergence of the LCA step [@hyv√§rinen_karhunen_oja_2001].

The pre-processed data then goes through the LCA step. The LCA step is based off of independent component analysis, where the separation vectors would be obtained by maximizing their statistical independence from each other. However, since the motor unit spike trains are extended along with the observations, they cannot be fully independent from each other. This is why LCA extracts separation vectors by maximizing sparsity instead of independence. Intuitively, this is done because a singular motor unit spike train will always be more sparse than the combination of multiple motor unit spike trains [@negro_muceli_castronovo_holobar_farina_2016]. First, the separation vector is initialized by using a time instance of high activity in the whitened data, as these time instances are likely to correspond to multiple motor unit firings. Using a contrast function that measures sparsity of the motor unit spike train, the estimated separation vector is iteratively updated. In each iteration, the estimated separation vectors are orthogonalized against previously accepted separation vectors and normalized, to increase the number of unique motor unit spike trains that are extracted.  The LCA step converges when the separation vector no longer changes, within a tolerance.

After the separation vector is extracted, it goes through the refinement step. This is done because the latent component analysis may converge to unreliable estimates and through refinement the quality of the estimate is increased. The refinement step is an iterative algorithm that maximizes the regularity of the motor unit spike train. This process is carried out under the assumption that singular motor units will fire off action potentials at a much more regular rate than combinations of motor units [@negro_muceli_castronovo_holobar_farina_2016]. First, the motor unit spike train is estimated by applying the separation vector to the pre-processed data. Then the firing times are determined by applying the peak-finding algorithm from @2020SciPy-NMeth. Of these firing times, the instances that correspond to small peaks in the spike train are separated away from the large peaks using the KMeans algorithm from @scikit-learn. The firing times corresponding to small peaks are discarded as they likely correspond to the firing occurrence of more than one motor unit [@negro_muceli_castronovo_holobar_farina_2016]. The information from the accepted firing times are used to update the separation vector. The iterative refinement process converges once the coefficient of variation of the time between firings increases, which in other words means the regularity decreases.

Once the refinement process is done, the refined separation vector is accepted based on a user-defined threshold of either the silhouette score between the signal and the noise or the pulse-to-noise ratio. The accepted separation vectors correspond to the motor units that the blind-source separation algorithm extracts from the raw signal.

We already implemented some improvements from the original algorithm provided by @negro_muceli_castronovo_holobar_farina_2016. We changed the initialization process of the separation vector as they originally stated that each separation vector is initialized with the singular time instance of highest activity in the pre-processed data. The problem with this approach is that, if the first separation vector is not accepted, then all subsequent separation vectors will not be accepted as nothing changes between iterations of the blind-source separation algorithm. We changed the initialization process to descend down the time instances of highest activity each iteration, so that each separation vector has a unique initialization. 

Another important change that we added is in how we orthogonalize the separation vectors. In @negro_muceli_castronovo_holobar_farina_2016, they "orthogonalize" the data by subtracting from the currently estimated separation vector the multiplication of the matrix of accepted separation vectors, its transpose, and the currently estimated separation vector. This method of "orthogonalization" doesn't really orthogonalize the separation vectors but instead subtracts some, but not all, of the information that is provided in the vector space of already accepted separation vectors. This approach causes many non-unique motor units to be extracted by the algorithm. We replaced this method of "orthogonalization" with Gram-Schmidt orthogonalization, which does actually orthogonalize the separation vectors and greatly decreases the amount of non-unique motor units identified.

A further improvement to the algorithm that we we did not have time to implement would be a re-learning feature. The user would run the algorithm on a sample of the data, and based on that sample identify firing times that are inaccurate. Then they would run the algorithm on the rest of the data and based on the firing times identified as inaccurate, the algorithm  would no longer make similar mistakes in the rest of the decomposition. Implementing this feature would be quite complex because it is unclear how this would be done. One idea was that we somehow change the initialization of the separation vectors so that they no longer identity the false firing times when applied to the pre-processed data. However, since the separation vector changes throughout the LCA and refinement processes, it would be hard to control the effect that it actually has on the estimated firing times. Another approach would be to influence the KMeans algorithm so that the threshold for the small peaks cluster includes the peaks that were  as false firings, in the hopes that future peaks of similar size are also false firings. The downside to this approach would be that we may increase the amount of incorrect identifications of large peaks as small peaks, which are discarded.
